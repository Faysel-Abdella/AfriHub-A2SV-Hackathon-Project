{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1D4OTI6bu0XBr6DI0dHJlE2DsAGCPfAYS","timestamp":1693731501665}],"gpuType":"T4","authorship_tag":"ABX9TyMUGC7f2U31WPWnAZj0qBJ7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_q9awdWxzkk","executionInfo":{"status":"ok","timestamp":1693731465839,"user_tz":-180,"elapsed":7438,"user":{"displayName":"fasil hawultie","userId":"10901863465555329766"}},"outputId":"ada2e90b-dfab-42f6-ddcf-a0b188819bec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Define the file path for \"a.csv\" in the root directory of Google Drive\n","file_path = \"/content/drive/MyDrive/train_v2.csv\"\n","\n","# Load the CSV file into a DataFrame\n"],"metadata":{"id":"dCP2nEKRx2PB","executionInfo":{"status":"ok","timestamp":1693731465843,"user_tz":-180,"elapsed":18,"user":{"displayName":"fasil hawultie","userId":"10901863465555329766"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from torch.utils.data import Dataset\n","\n","import torch\n","from sklearn import preprocessing\n","from torch.utils.data import DataLoader\n","from sklearn import model_selection\n","import torch.nn as nn\n","from sklearn import metrics\n","import numpy as np\n","\n","class JobDataset(Dataset):\n","    def __init__(self, user, job, proposal):\n","        self.user = user\n","        self.job = job\n","        self.proposal = proposal\n","\n","    def __len__(self):\n","        return len(self.user)\n","\n","    def __getitem__(self, item):\n","        user = self.user[item]\n","        job = self.job[item]\n","        proposal = self.proposal[item]\n","\n","        return {\n","            \"user\": torch.tensor(user, dtype=torch.long),\n","            \"job\": torch.tensor(job, dtype=torch.long),\n","            \"proposal\": torch.tensor(proposal, dtype=torch.float)\n","        }\n","\n","class RecsysModel(nn.Module):\n","    def __init__(self, num_users, num_jobs, embedding_dim=32):\n","        super(RecsysModel, self).__init__()\n","        self.user_embed = nn.Embedding(num_users, embedding_dim)\n","        self.job_embed = nn.Embedding(num_jobs, embedding_dim)\n","        self.out = nn.Linear(embedding_dim, 1)\n","\n","    def forward(self, user, job):\n","        user_embeds = self.user_embed(user)\n","        job_embeds = self.job_embed(job)\n","\n","        # You can add a scoring mechanism here, such as dot product or cosine similarity\n","        # Here, we'll use dot product as an example\n","        scores = torch.sum(user_embeds * job_embeds, dim=1, keepdim=True)\n","        return scores\n","\n","def train():\n","    # Load your input CSV data\n","    input_data = pd.read_csv('/content/drive/MyDrive/train_v2.csv')\n","\n","    lbl_user = preprocessing.LabelEncoder()\n","    lbl_job = preprocessing.LabelEncoder()\n","\n","    input_data['user'] = lbl_user.fit_transform(input_data['user'])\n","    input_data['job'] = lbl_job.fit_transform(input_data['job'])\n","\n","    # Save label encoders and number of users and jobs\n","    pd.DataFrame({'classes': lbl_user.classes_}).to_csv('/content/drive/MyDrive/newTrain/csvs/lbl_user_classes_02.csv', index=False)\n","    pd.DataFrame({'classes': lbl_job.classes_}).to_csv('/content/drive/MyDrive/newTrain/csvs/lbl_job_classes_02.csv', index=False)\n","    pd.DataFrame({'num_users': [len(lbl_user.classes_)], 'num_jobs': [len(lbl_job.classes_)]}).to_csv('/content/drive/MyDrive/newTrain/csvs/num_users_jobs_02.csv', index=False)\n","\n","    # train_data, valid_data = model_selection.train_test_split(\n","    #     input_data, test_size=0.1, random_state=42, stratify=input_data.proposal.values\n","    # )\n","    train_data, valid_data = model_selection.train_test_split(\n","        input_data, test_size=0.1, random_state=42\n","    )\n","\n","    train_dataset = JobDataset(\n","        user=train_data.user.values, job=train_data.job.values, proposal=train_data.proposal.values\n","    )\n","    valid_dataset = JobDataset(\n","        user=valid_data.user.values, job=valid_data.job.values, proposal=valid_data.proposal.values\n","    )\n","\n","    model = RecsysModel(num_users=len(lbl_user.classes_), num_jobs=len(lbl_job.classes_))\n","\n","    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n","\n","    # Define your loss function and optimizer\n","    criterion = nn.MSELoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","    # Training loop\n","    num_epochs = 10\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","        for batch in train_loader:\n","            user_ids = batch['user']\n","            job_ids = batch['job']\n","            proposals = batch['proposal']\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(user_ids, job_ids)\n","            loss = criterion(outputs, proposals.view(-1, 1))\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","        train_loss /= len(train_loader)\n","\n","        # Validation loop\n","        model.eval()\n","        val_loss = 0.0\n","        with torch.no_grad():\n","            for batch in valid_loader:\n","                user_ids = batch['user']\n","                job_ids = batch['job']\n","                proposals = batch['proposal']\n","\n","                outputs = model(user_ids, job_ids)\n","                loss = criterion(outputs, proposals.view(-1, 1))\n","\n","                val_loss += loss.item()\n","\n","            val_loss /= len(valid_loader)\n","\n","        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n","\n","    # Save the trained model\n","    torch.save(model.state_dict(), '/content/drive/MyDrive/newTrain/models/trained_model_02.pth')\n","\n","if __name__ == \"__main__\":\n","    train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXJ6Ou_Qx_SK","executionInfo":{"status":"ok","timestamp":1693731466663,"user_tz":-180,"elapsed":836,"user":{"displayName":"fasil hawultie","userId":"10901863465555329766"}},"outputId":"a5c9d84e-dfa7-4075-d1f7-32a72bfbde51"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Train Loss: 73.6616, Validation Loss: 86.8847\n","Epoch 2/10, Train Loss: 75.8126, Validation Loss: 86.8623\n","Epoch 3/10, Train Loss: 72.8465, Validation Loss: 86.8312\n","Epoch 4/10, Train Loss: 66.2741, Validation Loss: 86.8044\n","Epoch 5/10, Train Loss: 68.1539, Validation Loss: 86.7787\n","Epoch 6/10, Train Loss: 66.0811, Validation Loss: 86.7511\n","Epoch 7/10, Train Loss: 66.4566, Validation Loss: 86.7232\n","Epoch 8/10, Train Loss: 75.0649, Validation Loss: 86.6968\n","Epoch 9/10, Train Loss: 73.6374, Validation Loss: 86.6701\n","Epoch 10/10, Train Loss: 72.5559, Validation Loss: 86.6470\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from sklearn import preprocessing\n","from torch.utils.data import DataLoader\n","\n","# Load label encoders and number of users and jobs\n","lbl_user = preprocessing.LabelEncoder()\n","lbl_job = preprocessing.LabelEncoder()\n","lbl_user.classes_ = pd.read_csv('/content/drive/MyDrive/newTrain/csvs/lbl_user_classes_02.csv')['classes']\n","lbl_job.classes_ = pd.read_csv('/content/drive/MyDrive/newTrain/csvs/lbl_job_classes_02.csv')['classes']\n","num_users_jobs = pd.read_csv('/content/drive/MyDrive/newTrain/csvs/num_users_jobs_02.csv')\n","\n","class Tester:\n","    def __init__(self, model_path):\n","        self.model = RecsysModel(num_users=num_users_jobs['num_users'][0], num_jobs=num_users_jobs['num_jobs'][0])\n","        self.model.load_state_dict(torch.load(model_path))\n","        self.model.eval()\n","\n","    def test(self, user_ids, job_ids):\n","        recommendations = []\n","\n","        for user_id in user_ids:\n","            if user_id in lbl_user.classes_:\n","                user_idx = lbl_user.transform([user_id])[0]\n","                job_scores = self.predict_jobs(user_idx)\n","                recommendations.append({\"user_id\": user_id, \"job_scores\": job_scores})\n","            else:\n","                recommendations.append({\"user_id\": user_id, \"job_scores\": []})\n","\n","        return recommendations\n","\n","    def predict_jobs(self, user_idx):\n","        user_idx_tensor = torch.tensor([user_idx], dtype=torch.long)\n","        job_ids_tensor = torch.arange(num_users_jobs['num_jobs'][0], dtype=torch.long)\n","\n","        with torch.no_grad():\n","            job_scores = self.model(user_idx_tensor, job_ids_tensor).squeeze().numpy()\n","\n","        return job_scores\n","\n","def main():\n","    model_path = '/content/drive/MyDrive/newTrain/models/trained_model_02.pth'  # Specify the path to your trained model\n","    tester = Tester(model_path)\n","\n","    while True:\n","        user_id = input(\"Enter the user ID (or 'exit' to quit): \")\n","        if user_id.lower() == 'exit':\n","            break\n","\n","        # You can modify the job_ids list as needed to provide recommendations for specific jobs\n","        job_ids = lbl_job.classes_  # Recommend jobs for all available jobs\n","\n","        # Modify this line to pass only one user_id at a time\n","        recommendations = tester.test([user_id], job_ids)\n","\n","        print(f\"Job recommendations for user {user_id}:\")\n","\n","        for recommended_jobs in recommendations:\n","            print(f\"User: {recommended_jobs['user_id']}\")\n","\n","            if not recommended_jobs['job_scores']:\n","                print(\"No recommendations\")\n","            else:\n","                job_scores = recommended_jobs['job_scores']\n","                sorted_jobs = sorted(\n","                    zip(job_ids, job_scores),\n","                    key=lambda x: x[1],\n","                    reverse=True\n","                )\n","\n","                for job, score in sorted_jobs:\n","                    print(f\"Job: {job}, Score: {score}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oyv030wG1lCs","executionInfo":{"status":"ok","timestamp":1693731480058,"user_tz":-180,"elapsed":13495,"user":{"displayName":"fasil hawultie","userId":"10901863465555329766"}},"outputId":"292583d2-9c3e-4049-cf14-0bfd2c7452e7"},"execution_count":23,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter the user ID (or 'exit' to quit): 722\n","Job recommendations for user 722:\n","User: 722\n","No recommendations\n","Enter the user ID (or 'exit' to quit): exit\n"]}]},{"cell_type":"code","source":["\n"],"metadata":{"id":"gwVo5ohp1mVB","executionInfo":{"status":"ok","timestamp":1693731480060,"user_tz":-180,"elapsed":41,"user":{"displayName":"fasil hawultie","userId":"10901863465555329766"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3hJq30Jb9So7","executionInfo":{"status":"ok","timestamp":1693731480061,"user_tz":-180,"elapsed":37,"user":{"displayName":"fasil hawultie","userId":"10901863465555329766"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UFCsLH8E9Vk5","executionInfo":{"status":"ok","timestamp":1693731480062,"user_tz":-180,"elapsed":34,"user":{"displayName":"fasil hawultie","userId":"10901863465555329766"}}},"execution_count":23,"outputs":[]}]}